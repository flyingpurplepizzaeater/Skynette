---
phase: 10-built-in-tools
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/agent/tools/web_search.py
  - src/agent/tools/__init__.py
  - src/agent/registry/tool_registry.py
autonomous: true

must_haves:
  truths:
    - "Agent can search the web and return relevant results (TOOL-01)"
    - "Search degrades gracefully when API fails (try scraper)"
    - "Results include title, URL, and snippet for each result"
  artifacts:
    - path: "src/agent/tools/web_search.py"
      provides: "WebSearchTool, SearchProvider, DuckDuckGoProvider, ScraperFallbackProvider"
      exports: ["WebSearchTool"]
    - path: "src/agent/registry/tool_registry.py"
      provides: "WebSearchTool registration"
      contains: "WebSearchTool"
  key_links:
    - from: "src/agent/tools/web_search.py"
      to: "duckduckgo_search.DDGS"
      via: "DuckDuckGoProvider import"
      pattern: "from duckduckgo_search import DDGS"
    - from: "WebSearchTool.execute"
      to: "SearchProvider.search"
      via: "provider abstraction"
      pattern: "self._provider.search"
    - from: "src/agent/registry/tool_registry.py"
      to: "WebSearchTool"
      via: "register() call in _load_builtin_tools"
      pattern: "self.register\\(WebSearchTool\\)"
---

<objective>
Implement web search tool using DuckDuckGo API with scraper fallback for graceful degradation.

Purpose: Enables agent to search the web for information - a fundamental capability for answering questions and gathering data. Satisfies TOOL-01.

Output: `WebSearchTool` registered in ToolRegistry, using provider abstraction for flexibility.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-built-in-tools/10-CONTEXT.md
@.planning/phases/10-built-in-tools/10-RESEARCH.md

# Tool patterns
@src/agent/registry/base_tool.py
@src/agent/registry/mock_tool.py
@src/agent/models/tool.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement WebSearchTool with provider abstraction</name>
  <files>
    src/agent/tools/web_search.py
  </files>
  <action>
Create `src/agent/tools/web_search.py` with:

1. **SearchResult dataclass:**
```python
@dataclass
class SearchResult:
    title: str
    url: str
    snippet: str
```

2. **SearchProvider ABC:**
```python
class SearchProvider(ABC):
    @abstractmethod
    async def search(
        self,
        query: str,
        max_results: int = 10,
        time_filter: str | None = None,  # d, w, m, y
        domain_filter: str | None = None,  # site:example.com
    ) -> list[SearchResult]:
        pass
```

3. **DuckDuckGoProvider:**
- Use `duckduckgo_search.DDGS` for searches
- Run sync library in thread pool via `asyncio.to_thread()`
- Map DDGS results to SearchResult objects (title, href->url, body->snippet)
- Handle domain_filter by prepending `site:{domain}` to query
- Handle time_filter via DDGS timelimit parameter (d/w/m/y)

4. **ScraperFallbackProvider:**
- Use httpx to fetch DuckDuckGo HTML directly as fallback
- Parse results with beautifulsoup4
- Extract title, URL, snippet from search result divs
- Return empty list on any failure (graceful degradation)

5. **WebSearchTool (BaseTool subclass):**
```python
class WebSearchTool(BaseTool):
    name = "web_search"
    description = "Search the web and return relevant results with titles, URLs, and snippets."
    parameters_schema = {
        "type": "object",
        "properties": {
            "query": {"type": "string", "description": "Search query"},
            "max_results": {"type": "integer", "description": "Maximum results (default: 10)", "default": 10},
            "time_filter": {"type": "string", "enum": ["day", "week", "month", "year"], "description": "Filter by time period"},
            "domain_filter": {"type": "string", "description": "Restrict to domain (e.g., github.com)"}
        },
        "required": ["query"]
    }
```

Execute method:
- Try DuckDuckGoProvider first
- On exception, log warning and try ScraperFallbackProvider
- Return ToolResult.success_result with list of result dicts
- Map time_filter values: day->d, week->w, month->m, year->y

Add simple TTL caching (5 min) using a dict with (query, max_results, time_filter) as key and (results, timestamp) as value. Clean expired entries on each search.
  </action>
  <verify>
```python
import asyncio
from src.agent.tools.web_search import WebSearchTool, DuckDuckGoProvider
from src.agent.registry.base_tool import AgentContext

tool = WebSearchTool()
ctx = AgentContext(session_id="test")
result = asyncio.run(tool.execute({"query": "python programming"}, ctx))
assert result.success
assert isinstance(result.data, list)
print(f"Got {len(result.data)} results")
if result.data:
    print(f"First: {result.data[0]['title'][:50]}...")
```
  </verify>
  <done>WebSearchTool returns search results with title, URL, and snippet. Gracefully falls back to scraper on API failure.</done>
</task>

<task type="auto">
  <name>Task 2: Register WebSearchTool in ToolRegistry</name>
  <files>
    src/agent/registry/tool_registry.py
    src/agent/tools/__init__.py
  </files>
  <action>
1. Update `src/agent/tools/__init__.py` to export WebSearchTool:
```python
from src.agent.tools.web_search import WebSearchTool

__all__ = [
    # Base utilities
    "FileSystemValidator",
    "backup_before_modify",
    "cleanup_old_backups",
    # Tools
    "WebSearchTool",
]
```

2. Update `_load_builtin_tools()` in ToolRegistry to register WebSearchTool:
```python
def _load_builtin_tools(self) -> None:
    """Load built-in tools."""
    # Testing tool
    from src.agent.registry.mock_tool import MockTool
    self.register(MockTool)

    # Built-in tools
    from src.agent.tools import WebSearchTool
    self.register(WebSearchTool)

    logger.info(f"Loaded {len(self._tools)} built-in tools")
```
  </action>
  <verify>
```python
from src.agent.registry import get_tool_registry
registry = get_tool_registry()
assert 'web_search' in registry.tool_names
tool = registry.get_tool('web_search')
assert tool is not None
print(f"web_search tool registered: {tool.description[:50]}...")
```
  </verify>
  <done>WebSearchTool is registered in ToolRegistry and accessible via get_tool('web_search').</done>
</task>

</tasks>

<verification>
1. WebSearchTool executes and returns results
2. Results contain title, url, snippet fields
3. Tool is registered in ToolRegistry
4. Fallback provider activates when primary fails (can test by mocking DDGS import failure)

```bash
python -c "
import asyncio
from src.agent.registry import get_tool_registry
from src.agent.registry.base_tool import AgentContext

registry = get_tool_registry()
tool = registry.get_tool('web_search')
ctx = AgentContext(session_id='test')
result = asyncio.run(tool.execute({'query': 'test'}, ctx))
print(f'Success: {result.success}, Results: {len(result.data) if result.data else 0}')
"
```
</verification>

<success_criteria>
- [ ] WebSearchTool inherits from BaseTool with proper name/description/parameters_schema
- [ ] DuckDuckGoProvider fetches results via duckduckgo-search library
- [ ] ScraperFallbackProvider provides graceful degradation
- [ ] Time and domain filters work correctly
- [ ] Results cached for 5 minutes
- [ ] Tool registered in ToolRegistry as 'web_search'
</success_criteria>

<output>
After completion, create `.planning/phases/10-built-in-tools/10-02-SUMMARY.md`
</output>
