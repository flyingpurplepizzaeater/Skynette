---
phase: 09-mcp-integration
plan: 06
type: execute
wave: 5
depends_on: ["09-05"]
files_modified:
  - tests/agent/mcp/__init__.py
  - tests/agent/mcp/test_models.py
  - tests/agent/mcp/test_storage.py
  - tests/agent/mcp/test_client_manager.py
  - tests/agent/mcp/test_tool_adapter.py
  - tests/agent/mcp/test_integration.py
autonomous: true

must_haves:
  truths:
    - "Unit tests verify MCP model serialization and validation"
    - "Unit tests verify server config storage operations"
    - "Unit tests verify tool adapter wraps MCP tools correctly"
    - "Integration test connects to real MCP server and discovers tools"
  artifacts:
    - path: "tests/agent/mcp/test_models.py"
      provides: "Unit tests for MCP models"
      contains: "test_"
    - path: "tests/agent/mcp/test_storage.py"
      provides: "Unit tests for server storage"
      contains: "test_"
    - path: "tests/agent/mcp/test_tool_adapter.py"
      provides: "Unit tests for tool adapter"
      contains: "test_"
    - path: "tests/agent/mcp/test_integration.py"
      provides: "Integration tests for MCP connections"
      contains: "test_"
  key_links:
    - from: "tests/agent/mcp/test_integration.py"
      to: "src/agent/mcp/client/manager.py"
      via: "tests real connection"
      pattern: "get_mcp_client_manager"
---

<objective>
Create comprehensive unit and integration tests for the MCP integration to satisfy QUAL-02.

Purpose: Ensure MCP server connections work reliably. Per requirements, we need integration tests for MCP server connections to verify the system works end-to-end with real MCP servers.

Output: Test suite covering models, storage, tool adapter, and integration tests with real MCP servers (using npx-based servers as test targets).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-mcp-integration/09-CONTEXT.md
@.planning/phases/09-mcp-integration/09-01-SUMMARY.md
@.planning/phases/09-mcp-integration/09-02-SUMMARY.md
@.planning/phases/09-mcp-integration/09-03-SUMMARY.md

# Existing test patterns
@tests/agent/test_tool_registry.py (if exists, for patterns)
</context>

<tasks>

<task type="auto">
  <name>Task 1: MCP Model Tests</name>
  <files>
    tests/agent/mcp/__init__.py
    tests/agent/mcp/test_models.py
  </files>
  <action>
Create unit tests for MCP models verifying serialization and validation.

In `tests/agent/mcp/test_models.py`:

```python
"""Unit tests for MCP models."""

import pytest
from datetime import datetime, UTC

from src.agent.mcp.models.server import (
    MCPServerConfig,
    MCPServerStatus,
    TransportType,
    ServerCategory,
)
from src.agent.mcp.models.trust import TrustLevel, ToolApproval


class TestMCPServerConfig:
    """Tests for MCPServerConfig model."""

    def test_create_stdio_config(self):
        """Test creating a stdio transport config."""
        config = MCPServerConfig(
            name="Test Server",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@mcp/server-test"],
        )

        assert config.name == "Test Server"
        assert config.transport == TransportType.STDIO
        assert config.command == "npx"
        assert config.args == ["-y", "@mcp/server-test"]
        assert config.url is None
        assert config.id  # Should have auto-generated ID

    def test_create_http_config(self):
        """Test creating an HTTP transport config."""
        config = MCPServerConfig(
            name="Remote Server",
            transport=TransportType.HTTP,
            url="https://mcp.example.com/api",
            headers={"Authorization": "Bearer token"},
        )

        assert config.transport == TransportType.HTTP
        assert config.url == "https://mcp.example.com/api"
        assert config.headers == {"Authorization": "Bearer token"}
        assert config.command is None

    def test_default_trust_level(self):
        """Test default trust level is USER_ADDED."""
        config = MCPServerConfig(
            name="Test",
            transport=TransportType.STDIO,
            command="echo",
        )
        assert config.trust_level == TrustLevel.USER_ADDED

    def test_default_sandbox_enabled(self):
        """Test sandbox is enabled by default."""
        config = MCPServerConfig(
            name="Test",
            transport=TransportType.STDIO,
            command="echo",
        )
        assert config.sandbox_enabled is True

    def test_json_serialization(self):
        """Test config serializes to JSON correctly."""
        config = MCPServerConfig(
            name="Test",
            transport=TransportType.STDIO,
            command="npx",
            args=["test"],
            trust_level=TrustLevel.VERIFIED,
            category=ServerCategory.DEV_TOOLS,
        )

        json_data = config.model_dump_json()
        assert '"transport":"stdio"' in json_data.lower() or '"transport": "stdio"' in json_data.lower()
        assert '"trust_level":"verified"' in json_data.lower() or '"trust_level": "verified"' in json_data.lower()

    def test_from_json(self):
        """Test config can be loaded from JSON."""
        config = MCPServerConfig(
            name="Test",
            transport=TransportType.STDIO,
            command="npx",
        )
        json_data = config.model_dump_json()

        loaded = MCPServerConfig.model_validate_json(json_data)
        assert loaded.name == config.name
        assert loaded.transport == config.transport
        assert loaded.id == config.id


class TestMCPServerStatus:
    """Tests for MCPServerStatus model."""

    def test_create_connected_status(self):
        """Test creating connected status."""
        status = MCPServerStatus(
            server_id="test-123",
            connected=True,
            tools_count=5,
            latency_ms=15.5,
        )

        assert status.connected is True
        assert status.tools_count == 5
        assert status.latency_ms == 15.5

    def test_create_error_status(self):
        """Test creating error status."""
        status = MCPServerStatus(
            server_id="test-123",
            connected=False,
            error="Connection refused",
        )

        assert status.connected is False
        assert status.error == "Connection refused"


class TestTrustLevel:
    """Tests for TrustLevel enum."""

    def test_trust_levels_exist(self):
        """Test all trust levels are defined."""
        assert TrustLevel.BUILTIN
        assert TrustLevel.VERIFIED
        assert TrustLevel.USER_ADDED

    def test_trust_level_values(self):
        """Test trust level string values."""
        assert TrustLevel.BUILTIN.value == "builtin"
        assert TrustLevel.VERIFIED.value == "verified"
        assert TrustLevel.USER_ADDED.value == "user_added"


class TestToolApproval:
    """Tests for ToolApproval model."""

    def test_create_approval(self):
        """Test creating tool approval."""
        approval = ToolApproval(
            id="approval-1",
            server_id="server-1",
            tool_name="read_file",
            approved=True,
            approved_at=datetime.now(UTC),
        )

        assert approval.approved is True
        assert approval.tool_name == "read_file"
```

Create `tests/agent/mcp/__init__.py` as empty file.
  </action>
  <verify>
```bash
cd C:/Users/karlt/OneDrive/Desktop/Claude/skynette-repo
python -m pytest tests/agent/mcp/test_models.py -v --tb=short 2>/dev/null || python -m pytest tests/agent/mcp/test_models.py -v
```
  </verify>
  <done>
Model tests pass, verifying serialization, default values, and enum definitions.
  </done>
</task>

<task type="auto">
  <name>Task 2: Storage and Tool Adapter Tests</name>
  <files>
    tests/agent/mcp/test_storage.py
    tests/agent/mcp/test_tool_adapter.py
  </files>
  <action>
Create unit tests for server storage and tool adapter.

In `tests/agent/mcp/test_storage.py`:

```python
"""Unit tests for MCP server storage."""

import pytest
import tempfile
import os
from pathlib import Path

from src.agent.mcp.storage.server_storage import MCPServerStorage
from src.agent.mcp.models.server import (
    MCPServerConfig,
    TransportType,
    ServerCategory,
)
from src.agent.mcp.models.trust import TrustLevel, ToolApproval


@pytest.fixture
def temp_db():
    """Create temporary database for testing."""
    fd, path = tempfile.mkstemp(suffix=".db")
    os.close(fd)
    yield path
    os.unlink(path)


@pytest.fixture
def storage(temp_db):
    """Create storage instance with temp database."""
    return MCPServerStorage(temp_db)


class TestMCPServerStorage:
    """Tests for MCPServerStorage."""

    def test_save_and_load_server(self, storage):
        """Test saving and loading a server config."""
        config = MCPServerConfig(
            name="Test Server",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@mcp/test"],
            category=ServerCategory.DEV_TOOLS,
        )

        storage.save_server(config)
        loaded = storage.get_server(config.id)

        assert loaded is not None
        assert loaded.name == "Test Server"
        assert loaded.transport == TransportType.STDIO
        assert loaded.command == "npx"
        assert loaded.args == ["-y", "@mcp/test"]
        assert loaded.category == ServerCategory.DEV_TOOLS

    def test_list_servers(self, storage):
        """Test listing all servers."""
        config1 = MCPServerConfig(
            name="Server 1",
            transport=TransportType.STDIO,
            command="echo",
        )
        config2 = MCPServerConfig(
            name="Server 2",
            transport=TransportType.HTTP,
            url="https://example.com",
            enabled=False,
        )

        storage.save_server(config1)
        storage.save_server(config2)

        all_servers = storage.list_servers()
        assert len(all_servers) == 2

        enabled_only = storage.list_servers(enabled_only=True)
        assert len(enabled_only) == 1
        assert enabled_only[0].name == "Server 1"

    def test_delete_server(self, storage):
        """Test deleting a server."""
        config = MCPServerConfig(
            name="To Delete",
            transport=TransportType.STDIO,
            command="echo",
        )

        storage.save_server(config)
        assert storage.get_server(config.id) is not None

        result = storage.delete_server(config.id)
        assert result is True
        assert storage.get_server(config.id) is None

    def test_get_servers_by_category(self, storage):
        """Test filtering servers by category."""
        config1 = MCPServerConfig(
            name="Dev Tool",
            transport=TransportType.STDIO,
            command="echo",
            category=ServerCategory.DEV_TOOLS,
        )
        config2 = MCPServerConfig(
            name="Browser Tool",
            transport=TransportType.STDIO,
            command="echo",
            category=ServerCategory.BROWSER_TOOLS,
        )

        storage.save_server(config1)
        storage.save_server(config2)

        dev_tools = storage.get_servers_by_category(ServerCategory.DEV_TOOLS)
        assert len(dev_tools) == 1
        assert dev_tools[0].name == "Dev Tool"

    def test_tool_approval_operations(self, storage):
        """Test tool approval save and load."""
        config = MCPServerConfig(
            name="Server",
            transport=TransportType.STDIO,
            command="echo",
        )
        storage.save_server(config)

        approval = ToolApproval(
            id="approval-1",
            server_id=config.id,
            tool_name="dangerous_tool",
            approved=True,
        )
        storage.save_tool_approval(approval)

        assert storage.is_tool_approved(config.id, "dangerous_tool") is True
        assert storage.is_tool_approved(config.id, "other_tool") is False


class TestServerConfigPersistence:
    """Test complex config persistence."""

    def test_env_and_headers_persist(self, storage):
        """Test that env vars and headers persist correctly."""
        config = MCPServerConfig(
            name="Complex Config",
            transport=TransportType.HTTP,
            url="https://api.example.com",
            env={"API_KEY": "secret", "DEBUG": "true"},
            headers={"Authorization": "Bearer token"},
        )

        storage.save_server(config)
        loaded = storage.get_server(config.id)

        assert loaded.env == {"API_KEY": "secret", "DEBUG": "true"}
        assert loaded.headers == {"Authorization": "Bearer token"}
```

In `tests/agent/mcp/test_tool_adapter.py`:

```python
"""Unit tests for MCP tool adapter."""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch

from src.agent.mcp.adapter.tool_adapter import MCPToolAdapter
from src.agent.mcp.models.trust import TrustLevel
from src.agent.registry.base_tool import AgentContext
from src.agent.models.tool import ToolResult


class TestMCPToolAdapter:
    """Tests for MCPToolAdapter."""

    @pytest.fixture
    def mock_mcp_tool(self):
        """Create a mock MCP tool definition."""
        return {
            "name": "read_file",
            "description": "Read contents of a file",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "File path"},
                },
                "required": ["path"],
            },
        }

    @pytest.fixture
    def adapter(self, mock_mcp_tool):
        """Create an adapter instance."""
        return MCPToolAdapter(
            mcp_tool=mock_mcp_tool,
            server_id="test-server-12345678",
            server_name="Filesystem",
            trust_level=TrustLevel.VERIFIED,
        )

    def test_namespaced_tool_name(self, adapter):
        """Test tool name is properly namespaced."""
        assert adapter.name == "mcp_test-ser_read_file"
        assert adapter.original_name == "read_file"

    def test_description_includes_source(self, adapter):
        """Test description includes server name."""
        assert "[Filesystem]" in adapter.description
        assert "Read contents" in adapter.description

    def test_parameters_schema_preserved(self, adapter, mock_mcp_tool):
        """Test parameters schema is preserved."""
        assert adapter.parameters_schema == mock_mcp_tool["inputSchema"]

    def test_get_definition(self, adapter):
        """Test get_definition returns proper ToolDefinition."""
        defn = adapter.get_definition()

        assert defn.name == adapter.name
        assert "Filesystem" in defn.description
        assert defn.category == "mcp:filesystem"
        assert defn.requires_approval is False  # VERIFIED doesn't require approval

    def test_user_added_requires_approval(self, mock_mcp_tool):
        """Test USER_ADDED tools require approval."""
        adapter = MCPToolAdapter(
            mcp_tool=mock_mcp_tool,
            server_id="untrusted-123",
            server_name="Unknown Server",
            trust_level=TrustLevel.USER_ADDED,
        )

        defn = adapter.get_definition()
        assert defn.requires_approval is True

    def test_get_mcp_metadata(self, adapter):
        """Test metadata extraction."""
        meta = adapter.get_mcp_metadata()

        assert meta["server_id"] == "test-server-12345678"
        assert meta["server_name"] == "Filesystem"
        assert meta["original_name"] == "read_file"
        assert meta["trust_level"] == "verified"

    def test_openai_format(self, adapter):
        """Test OpenAI format conversion."""
        defn = adapter.get_definition()
        openai_format = defn.to_openai_format()

        assert openai_format["type"] == "function"
        assert openai_format["function"]["name"] == adapter.name
        assert "properties" in openai_format["function"]["parameters"]

    def test_anthropic_format(self, adapter):
        """Test Anthropic format conversion."""
        defn = adapter.get_definition()
        anthropic_format = defn.to_anthropic_format()

        assert anthropic_format["name"] == adapter.name
        assert "input_schema" in anthropic_format

    @pytest.mark.asyncio
    async def test_execute_success(self, adapter):
        """Test successful tool execution."""
        context = AgentContext(session_id="test-session")

        # Mock the manager
        mock_result = {
            "success": True,
            "content": [{"type": "text", "text": "file contents here"}],
        }

        with patch("src.agent.mcp.adapter.tool_adapter.get_mcp_client_manager") as mock_get_manager:
            mock_manager = AsyncMock()
            mock_manager.call_tool.return_value = mock_result
            mock_get_manager.return_value = mock_manager

            result = await adapter.execute({"path": "/test/file.txt"}, context)

            assert result.success is True
            assert result.data == "file contents here"
            mock_manager.call_tool.assert_called_once_with(
                "test-server-12345678",
                "read_file",
                {"path": "/test/file.txt"},
            )

    @pytest.mark.asyncio
    async def test_execute_error(self, adapter):
        """Test tool execution with error."""
        context = AgentContext(session_id="test-session")

        mock_result = {
            "success": False,
            "content": [{"type": "text", "text": "File not found"}],
        }

        with patch("src.agent.mcp.adapter.tool_adapter.get_mcp_client_manager") as mock_get_manager:
            mock_manager = AsyncMock()
            mock_manager.call_tool.return_value = mock_result
            mock_get_manager.return_value = mock_manager

            result = await adapter.execute({"path": "/nonexistent"}, context)

            assert result.success is False
            assert "File not found" in result.error
```
  </action>
  <verify>
```bash
cd C:/Users/karlt/OneDrive/Desktop/Claude/skynette-repo
python -m pytest tests/agent/mcp/test_storage.py tests/agent/mcp/test_tool_adapter.py -v --tb=short 2>/dev/null || python -m pytest tests/agent/mcp/test_storage.py tests/agent/mcp/test_tool_adapter.py -v
```
  </verify>
  <done>
Storage tests verify CRUD operations and category filtering. Tool adapter tests verify namespacing, format conversion, and execution mocking.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integration Tests</name>
  <files>
    tests/agent/mcp/test_integration.py
  </files>
  <action>
Create integration tests that connect to real MCP servers.

In `tests/agent/mcp/test_integration.py`:

```python
"""Integration tests for MCP server connections.

These tests require npx to be installed and internet access.
They are marked with pytest.mark.integration and can be skipped
with: pytest -m "not integration"
"""

import pytest
import asyncio
import shutil

from src.agent.mcp.client.manager import get_mcp_client_manager, MCPClientManager
from src.agent.mcp.models.server import MCPServerConfig, TransportType
from src.agent.mcp.models.trust import TrustLevel
from src.agent.registry.tool_registry import ToolRegistry


# Check if npx is available
NPX_AVAILABLE = shutil.which("npx") is not None


@pytest.fixture
async def manager():
    """Create and initialize a fresh manager for each test."""
    # Create a new manager instance (bypass singleton for testing)
    mgr = MCPClientManager.__new__(MCPClientManager)
    mgr._initialized = False
    await mgr.initialize()
    yield mgr
    await mgr.disconnect_all()


@pytest.mark.integration
@pytest.mark.skipif(not NPX_AVAILABLE, reason="npx not available")
class TestMCPClientIntegration:
    """Integration tests for MCP client connections."""

    @pytest.mark.asyncio
    async def test_connect_to_fetch_server(self, manager):
        """Test connecting to the fetch MCP server."""
        config = MCPServerConfig(
            name="Test Fetch",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        # Connect
        connection = await manager.connect(config)
        assert connection is not None
        assert connection.server_id == config.id

        # List tools
        tools = await connection.list_tools()
        assert len(tools) > 0

        # Find fetch tool
        tool_names = [t["name"] for t in tools]
        assert "fetch" in tool_names

        # Verify tool has schema
        fetch_tool = next(t for t in tools if t["name"] == "fetch")
        assert "inputSchema" in fetch_tool or "input_schema" in fetch_tool

    @pytest.mark.asyncio
    async def test_call_fetch_tool(self, manager):
        """Test calling the fetch tool."""
        config = MCPServerConfig(
            name="Test Fetch",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        await manager.connect(config)

        # Call fetch tool
        result = await manager.call_tool(
            config.id,
            "fetch",
            {"url": "https://httpbin.org/get"},
        )

        assert result["success"] is True
        assert len(result["content"]) > 0

    @pytest.mark.asyncio
    async def test_reconnect_after_disconnect(self, manager):
        """Test that we can reconnect after disconnecting."""
        config = MCPServerConfig(
            name="Test Fetch",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        # First connection
        conn1 = await manager.connect(config)
        tools1 = await conn1.list_tools()

        # Disconnect
        await manager.disconnect(config.id)
        assert manager.get_connection(config.id) is None

        # Reconnect
        conn2 = await manager.connect(config)
        tools2 = await conn2.list_tools()

        # Should have same tools
        assert len(tools1) == len(tools2)

    @pytest.mark.asyncio
    async def test_multiple_servers(self, manager):
        """Test connecting to multiple servers simultaneously."""
        config1 = MCPServerConfig(
            name="Fetch 1",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        config2 = MCPServerConfig(
            name="Fetch 2",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        # Connect both
        await manager.connect(config1)
        await manager.connect(config2)

        # Both should be connected
        connections = manager.list_connections()
        assert len(connections) == 2


@pytest.mark.integration
@pytest.mark.skipif(not NPX_AVAILABLE, reason="npx not available")
class TestToolRegistryIntegration:
    """Integration tests for tool registry with MCP tools."""

    @pytest.fixture
    def registry(self):
        """Create a fresh registry for testing."""
        reg = ToolRegistry.__new__(ToolRegistry)
        reg._initialized = False
        reg._tools = {}
        reg._mcp_tools = {}
        return reg

    @pytest.mark.asyncio
    async def test_register_mcp_tools_from_connection(self, manager, registry):
        """Test registering MCP tools in the registry."""
        config = MCPServerConfig(
            name="Fetch Server",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        # Connect and get tools
        connection = await manager.connect(config)
        mcp_tools = await connection.list_tools()

        # Register in registry
        count = registry.register_mcp_tools_from_server(
            server_id=config.id,
            server_name=config.name,
            trust_level=config.trust_level,
            tools=mcp_tools,
        )

        assert count > 0
        assert len(registry.get_mcp_tools()) == count

        # Tools should appear in definitions
        all_defs = registry.get_all_definitions()
        mcp_defs = [d for d in all_defs if d.name.startswith("mcp_")]
        assert len(mcp_defs) == count

    @pytest.mark.asyncio
    async def test_tool_execution_through_registry(self, manager, registry):
        """Test executing MCP tool through registry."""
        config = MCPServerConfig(
            name="Fetch Server",
            transport=TransportType.STDIO,
            command="npx",
            args=["-y", "@modelcontextprotocol/server-fetch"],
            trust_level=TrustLevel.VERIFIED,
            sandbox_enabled=False,
        )

        # Setup
        connection = await manager.connect(config)
        mcp_tools = await connection.list_tools()
        registry.register_mcp_tools_from_server(
            server_id=config.id,
            server_name=config.name,
            trust_level=config.trust_level,
            tools=mcp_tools,
        )

        # Find the fetch tool in registry
        fetch_tool = None
        for tool in registry.get_mcp_tools():
            if tool.original_name == "fetch":
                fetch_tool = tool
                break

        assert fetch_tool is not None

        # Execute through adapter
        from src.agent.registry.base_tool import AgentContext

        context = AgentContext(session_id="test-session")
        result = await fetch_tool.execute(
            {"url": "https://httpbin.org/get"},
            context,
        )

        assert result.success is True
```
  </action>
  <verify>
```bash
cd C:/Users/karlt/OneDrive/Desktop/Claude/skynette-repo
# Run only unit tests (not integration) first
python -m pytest tests/agent/mcp/ -v --ignore=tests/agent/mcp/test_integration.py --tb=short 2>/dev/null || python -m pytest tests/agent/mcp/ -v --ignore=tests/agent/mcp/test_integration.py

# If npx available, run integration tests too
which npx && python -m pytest tests/agent/mcp/test_integration.py -v -m integration --tb=short || echo "Skipping integration tests (npx not available)"
```
  </verify>
  <done>
Integration tests connect to real MCP servers (fetch server via npx), verify tool discovery, and test tool execution through the full stack.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. All unit tests pass:
```bash
python -m pytest tests/agent/mcp/test_models.py tests/agent/mcp/test_storage.py tests/agent/mcp/test_tool_adapter.py -v
```

2. Integration tests pass (when npx available):
```bash
python -m pytest tests/agent/mcp/test_integration.py -v -m integration
```

3. Full test suite:
```bash
python -m pytest tests/agent/mcp/ -v
```
</verification>

<success_criteria>
- Model tests verify serialization, defaults, and enum values
- Storage tests verify CRUD, category filtering, and tool approvals
- Tool adapter tests verify namespacing, format conversion, and mocked execution
- Integration tests connect to real MCP server (fetch) and verify tool discovery
- Integration tests execute a tool and verify result
- All tests pass with `pytest tests/agent/mcp/ -v`
</success_criteria>

<output>
After completion, create `.planning/phases/09-mcp-integration/09-06-SUMMARY.md`
</output>
