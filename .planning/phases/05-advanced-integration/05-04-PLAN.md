---
phase: 05-advanced-integration
plan: 04
type: execute
wave: 2
depends_on: ["05-01", "05-02", "05-03"]
files_modified:
  - tests/e2e/test_code_editor_workflow.py
  - tests/e2e/test_rag_integration.py
  - tests/e2e/test_critical_journeys.py
  - tests/unit/test_security_audit.py
  - src/ai/security.py
autonomous: true

must_haves:
  truths:
    - "Critical user journeys pass E2E tests"
    - "API keys are not exposed in process memory (security audit)"
    - "All Phase 5 features have test coverage"
    - "Security audit confirms no plaintext key storage"
  artifacts:
    - path: "tests/e2e/test_critical_journeys.py"
      provides: "E2E tests for critical user paths"
      contains: "test_workflow_creation_and_execution"
    - path: "tests/unit/test_security_audit.py"
      provides: "Security audit tests for API key handling"
      contains: "test_api_key_not_in_memory"
  key_links:
    - from: "tests/e2e/test_code_editor_workflow.py"
      to: "WorkflowBridge"
      via: "UI automation opening workflow in editor"
      pattern: "code.*editor.*workflow"
    - from: "tests/unit/test_security_audit.py"
      to: "src/ai/security.py"
      via: "keyring storage verification"
      pattern: "keyring\\.(get|set)_password"
---

<objective>
Create comprehensive E2E tests for critical user journeys and perform security audit for API key exposure.

Purpose: Ensure all major features work end-to-end from user perspective, and confirm API keys are securely stored without exposure in memory or logs.

Output: E2E test suite for critical journeys (workflows, code editor, RAG, AI chat), security audit tests verifying keyring usage and memory safety.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-advanced-integration/05-RESEARCH.md
@.planning/phases/05-advanced-integration/05-CONTEXT.md

# Key existing files
@tests/e2e/conftest.py
@src/ai/security.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create E2E tests for critical user journeys</name>
  <files>
    tests/e2e/test_critical_journeys.py
  </files>
  <action>
Create comprehensive E2E test suite covering critical user paths:

1. Test workflow creation and execution:
   ```python
   def test_workflow_creation_and_execution(page, selectors, helpers):
       """User can create a workflow, add nodes, and execute it."""
       # Navigate to workflows
       helpers.navigate_to(page, "workflows")
       page.wait_for_timeout(1000)

       # Create new workflow
       page.locator(selectors.NEW_WORKFLOW_BTN).first.click()
       page.wait_for_timeout(500)

       # Fill name in dialog
       inputs = page.locator("input, [role='textbox']")
       if inputs.count() > 0:
           inputs.first.fill("E2E Test Workflow")
       page.locator(selectors.CREATE_BTN).first.click()
       page.wait_for_timeout(1000)

       # Verify workflow created (should be in editor)
       assert page.locator("text=E2E Test Workflow").is_visible()

       # Add a node (Manual Trigger)
       # ... add node via palette click

       # Save workflow
       page.locator(selectors.SAVE_BTN).first.click()
       page.wait_for_timeout(500)

       # Execute workflow
       page.locator(selectors.RUN_BTN).first.click()
       page.wait_for_timeout(2000)

       # Verify execution in runs view
       helpers.navigate_to(page, "runs")
       page.wait_for_timeout(1000)
       assert page.locator("text=E2E Test Workflow").is_visible()
   ```

2. Test AI chat with code context:
   ```python
   def test_ai_chat_with_context(page, selectors, helpers):
       """User can chat with AI and receive contextual responses."""
       helpers.navigate_to(page, "ai_hub")
       page.wait_for_timeout(1000)

       # Find and fill chat input
       chat_input = page.locator("textarea").first
       chat_input.fill("Hello, what can you help me with?")

       # Send message
       send_btn = page.locator("[aria-label*='Send'], button:has-text('Send')").first
       send_btn.click()
       page.wait_for_timeout(3000)  # Wait for AI response

       # Verify response appears (mock AI in test mode)
       assert page.locator("flt-semantics:has-text('assistant')").is_visible() or \
              page.locator("text=I can help").is_visible()
   ```

3. Test code editor file operations:
   ```python
   def test_code_editor_file_operations(page, selectors, helpers, tmp_path):
       """User can open, edit, and save files in code editor."""
       # This test requires a temp directory with test files
       # Create test file
       test_file = tmp_path / "test.py"
       test_file.write_text("# Test file\nprint('hello')")

       helpers.navigate_to(page, "code_editor")  # Assuming nav item exists
       page.wait_for_timeout(1000)

       # Open folder picker (may need to mock or skip in CI)
       # ... file tree interaction

       # Verify editor shows content
       # ... content verification
   ```

4. Test navigation between all views:
   ```python
   def test_navigation_all_views(page, selectors, helpers):
       """User can navigate to all main views without errors."""
       views = ["workflows", "ai_hub", "agents", "plugins", "runs", "settings"]
       for view in views:
           helpers.navigate_to(page, view)
           page.wait_for_timeout(500)
           # Verify no error messages
           assert not page.locator("text=Error").is_visible()
   ```

5. Test settings persistence:
   ```python
   def test_settings_persistence(page, selectors, helpers):
       """User settings persist across navigation."""
       helpers.navigate_to(page, "settings")
       page.wait_for_timeout(1000)
       # Toggle a setting, navigate away, come back, verify
   ```
  </action>
  <verify>
    pytest tests/e2e/test_critical_journeys.py -v --headed (for debugging)
    pytest tests/e2e/test_critical_journeys.py -v (headless)
  </verify>
  <done>
    E2E tests cover: workflow CRUD, AI chat, code editor, navigation, settings
    Tests run in headless mode for CI
    Tests use mock AI provider (SKYNETTE_MOCK_AI=true)
    QUAL-04 requirement satisfied
  </done>
</task>

<task type="auto">
  <name>Task 2: Create security audit tests for API key handling</name>
  <files>
    tests/unit/test_security_audit.py
    src/ai/security.py
  </files>
  <action>
Create security audit test suite:

1. Test keyring usage (not plaintext):
   ```python
   import gc
   from src.ai.security import store_api_key, get_api_key, delete_api_key

   def test_api_key_uses_keyring():
       """API keys are stored via keyring, not plaintext files."""
       import keyring
       from unittest.mock import patch

       with patch.object(keyring, 'set_password') as mock_set:
           store_api_key('test_provider', 'sk-test-key')
           mock_set.assert_called_once()
           args = mock_set.call_args[0]
           assert args[0] == 'skynette-ai'  # Service name
           assert args[1] == 'test_provider'
           assert args[2] == 'sk-test-key'
   ```

2. Test API key not logged:
   ```python
   import logging

   def test_api_key_not_logged(caplog):
       """API keys should never appear in logs."""
       test_key = "sk-super-secret-key-12345"

       with caplog.at_level(logging.DEBUG):
           store_api_key('test_provider', test_key)
           get_api_key('test_provider')
           delete_api_key('test_provider')

       # Check no log entry contains the key
       for record in caplog.records:
           assert test_key not in record.message
           assert "sk-super-secret" not in record.message
   ```

3. Test memory clearing (best effort):
   ```python
   def test_api_key_garbage_collection():
       """Verify key variables can be garbage collected."""
       import weakref

       key = "sk-test-memory-key"
       weak_ref = weakref.ref(key)

       del key
       gc.collect()

       # Note: Python string interning may keep small strings alive
       # This test documents the behavior rather than guaranteeing cleanup
   ```

4. Test no keys in environment variables:
   ```python
   import os

   def test_no_api_keys_in_env():
       """API keys should not be stored in environment variables."""
       # Check common patterns
       for key, value in os.environ.items():
           if 'API' in key.upper() or 'KEY' in key.upper():
               # Allow test mode markers
               if key == 'SKYNETTE_MOCK_AI':
                   continue
               # Fail if looks like an actual key
               assert not (value.startswith('sk-') or len(value) > 30)
   ```

5. Test key retrieval doesn't expose in exception:
   ```python
   def test_key_not_in_exception():
       """Exceptions should not contain API keys."""
       from unittest.mock import patch

       with patch('keyring.get_password', side_effect=Exception("Test error")):
           result = get_api_key('nonexistent_provider')
           # Should return None, not raise
           assert result is None
   ```

6. Audit existing security.py for improvements:
   - Verify no debug logging of key values
   - Verify exception handling doesn't expose keys
   - Add TODO if gc.collect() should be called after key operations
  </action>
  <verify>
    pytest tests/unit/test_security_audit.py -v
    All security audit tests pass
    No API keys found in logs or environment
  </verify>
  <done>
    Security audit confirms keyring usage for key storage
    Tests verify keys not logged or exposed in exceptions
    Memory handling documented (Python string interning caveat)
    QUAL-05 requirement satisfied
  </done>
</task>

<task type="auto">
  <name>Task 3: Create integration tests for Phase 5 features</name>
  <files>
    tests/e2e/test_code_editor_workflow.py
    tests/e2e/test_rag_integration.py
    tests/unit/test_phase5_integration.py
  </files>
  <action>
Create integration tests for new Phase 5 features:

1. Test workflow editing in code editor (test_code_editor_workflow.py):
   ```python
   # Unit/integration test (not full E2E)
   import pytest
   from src.ui.views.code_editor.workflow_bridge import WorkflowBridge, WorkflowFormat
   from src.data.storage import get_storage
   from src.core.workflow.models import Workflow

   @pytest.fixture
   def sample_workflow():
       workflow = Workflow(name="Test Workflow", description="For testing")
       return workflow

   def test_workflow_load_as_yaml(sample_workflow):
       storage = get_storage()
       storage.save_workflow(sample_workflow)

       bridge = WorkflowBridge(storage)
       yaml_code = bridge.load_as_code(sample_workflow.id, WorkflowFormat.YAML)

       assert "name: Test Workflow" in yaml_code

   def test_workflow_roundtrip(sample_workflow):
       storage = get_storage()
       storage.save_workflow(sample_workflow)

       bridge = WorkflowBridge(storage)
       yaml_code = bridge.load_as_code(sample_workflow.id, WorkflowFormat.YAML)

       # Modify
       yaml_code = yaml_code.replace("Test Workflow", "Modified Workflow")

       # Save back
       success, error = bridge.save_from_code(sample_workflow.id, yaml_code, WorkflowFormat.YAML)
       assert success, error

       # Reload and verify
       reloaded = storage.load_workflow(sample_workflow.id)
       assert reloaded.name == "Modified Workflow"
   ```

2. Test RAG context retrieval (test_rag_integration.py):
   ```python
   import pytest
   import tempfile
   from pathlib import Path
   from src.rag.project_indexer import ProjectIndexer
   from src.rag.chromadb_client import ChromaDBClient
   from src.rag.embeddings import EmbeddingManager

   @pytest.fixture
   def temp_project(tmp_path):
       # Create test files
       (tmp_path / "main.py").write_text("def main():\n    print('Hello')")
       (tmp_path / "utils.py").write_text("def helper():\n    return 42")
       return tmp_path

   @pytest.mark.asyncio
   async def test_project_indexing(temp_project):
       chromadb = ChromaDBClient(str(temp_project / ".rag"))
       await chromadb.initialize()
       embeddings = EmbeddingManager()

       indexer = ProjectIndexer(chromadb, embeddings)
       stats = await indexer.index_project(str(temp_project))

       assert stats["indexed"] >= 2  # main.py and utils.py

   @pytest.mark.asyncio
   async def test_rag_query(temp_project):
       chromadb = ChromaDBClient(str(temp_project / ".rag"))
       await chromadb.initialize()
       embeddings = EmbeddingManager()

       indexer = ProjectIndexer(chromadb, embeddings)
       await indexer.index_project(str(temp_project))

       results = await indexer.query_context("main function", str(temp_project))
       assert len(results) > 0
       assert any("main" in r.get("content", "") for r in results)
   ```

3. Run comprehensive test coverage check:
   ```python
   # tests/unit/test_phase5_integration.py
   def test_all_phase5_modules_importable():
       """Verify all Phase 5 modules can be imported."""
       from src.ui.views.code_editor.workflow_bridge import WorkflowBridge
       from src.rag.project_indexer import ProjectIndexer
       from src.rag.dimension_validator import DimensionValidator
       from src.core.nodes.execution.code_runner import CodeExecutionNode
       from src.ui.views.code_editor.ai_panel.rag_context import RAGContextProvider

       assert WorkflowBridge is not None
       assert ProjectIndexer is not None
       assert DimensionValidator is not None
       assert CodeExecutionNode is not None
       assert RAGContextProvider is not None
   ```
  </action>
  <verify>
    pytest tests/e2e/test_code_editor_workflow.py tests/e2e/test_rag_integration.py tests/unit/test_phase5_integration.py -v
    pytest tests/ -v --cov=src --cov-report=term-missing (check coverage)
  </verify>
  <done>
    Integration tests cover workflow bridge, RAG indexing, context retrieval
    All Phase 5 modules importable and functional
    Test coverage report shows adequate coverage
    STAB-05 requirement satisfied for Phase 5 features
  </done>
</task>

</tasks>

<verification>
After all tasks:
1. pytest tests/e2e/ -v --tb=short - All E2E tests pass
2. pytest tests/unit/test_security_audit.py -v - Security audit passes
3. pytest tests/ -v --cov=src --cov-report=term-missing - Check coverage
4. Manual: Run full test suite, verify no regressions
5. Review security.py for any exposed key patterns
</verification>

<success_criteria>
- E2E tests cover all critical user journeys (workflow, chat, editor, navigation)
- Security audit confirms API keys stored via keyring, not exposed
- Integration tests verify Phase 5 features work together
- All tests pass in CI environment (headless, mock AI)
- STAB-05, QUAL-04, QUAL-05 requirements satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/05-advanced-integration/05-04-SUMMARY.md`
</output>
